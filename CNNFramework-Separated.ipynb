{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 101\n",
    "h = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open(\"training_separated.p\", 'rb'))\n",
    "X = data[0]\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape\n",
      "(5404, 101, 101, 1)\n",
      "(5404, 2)\n",
      "Testing Shape\n",
      "(954, 101, 101, 1)\n",
      "(954, 2)\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "print(\"Training Shape\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Testing Shape\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PictureHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "\n",
    "        self.training_images = X_train\n",
    "        self.training_labels = y_train\n",
    "        \n",
    "        self.testing_images = X_test\n",
    "        self.testing_labels = y_test\n",
    "    \n",
    "    def getTesting(self, batch_size):\n",
    "        # shuffle data\n",
    "        p = np.random.permutation(len(self.testing_images))\n",
    "        self.testing_images = self.testing_images[p]\n",
    "        self.testing_labels = self.testing_labels[p]   \n",
    "        if (batch_size < self.testing_images.shape[0]):\n",
    "            x = self.testing_images[:batch_size]\n",
    "            y = self.testing_labels[:batch_size]\n",
    "        else:\n",
    "            x = self.testing_images\n",
    "            y = self.testing_labels\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        \n",
    "        if (self.i + batch_size >= self.training_images.shape[0]):\n",
    "            p = numpy.random.permutation(len(self.training_images))\n",
    "            self.training_images = self.training_images[p]\n",
    "            self.training_labels = self.training_labels[p]\n",
    "            \n",
    "        x = self.training_images[self.i:self.i+batch_size]\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "            \n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 101, 101, 1)\n",
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "ph = PictureHelper()\n",
    "x, y = ph.getTesting(10)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "\n",
    "** Import tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,w,h,1])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[2,2,1,128])\n",
    "convo_2 = convolutional_layer(convo_1,shape=[2,2,128,128])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "convo_3 = convolutional_layer(convo_2_pooling,shape=[2,2,128,128])\n",
    "convo_4 = convolutional_layer(convo_3,shape=[2,2,128,128])\n",
    "convo_4_pooling = max_pool_2by2(convo_4)\n",
    "\n",
    "convo_5 = convolutional_layer(convo_4_pooling,shape=[2,2,128,128])\n",
    "convo_6 = convolutional_layer(convo_5,shape=[2,2,128,128])\n",
    "convo_7 = convolutional_layer(convo_6,shape=[2,2,128,64])\n",
    "convo_7_pooling = max_pool_2by2(convo_7)\n",
    "\n",
    "convo_8 = convolutional_layer(convo_7_pooling, shape=[2,2,64,256])\n",
    "convo_9 = convolutional_layer(convo_8, shape=[2,2,256,256])\n",
    "convo_10 = convolutional_layer(convo_9, shape=[2,2,256,128])\n",
    "convo_10_pooling = max_pool_2by2(convo_10)\n",
    "\n",
    "convo_11 = convolutional_layer(convo_10_pooling, shape=[2,2,128,256])\n",
    "convo_12 = convolutional_layer(convo_11, shape=[2,2,256,256])\n",
    "convo_13 = convolutional_layer(convo_12, shape=[2,2,256,128])\n",
    "\n",
    "new_w = math.ceil(w / 16)\n",
    "new_h = math.ceil(h / 16)\n",
    "\n",
    "num_features = 128\n",
    "\n",
    "convo_13_flat = tf.reshape(convo_13,[-1,new_h*new_w*num_features])\n",
    "\n",
    "full_layer_1 = tf.nn.relu(normal_full_layer(convo_13_flat,1024))\n",
    "\n",
    "full_layer_2 = tf.nn.relu(normal_full_layer(full_layer_1,1024))\n",
    "\n",
    "full_dropout = tf.nn.dropout(full_layer_2,keep_prob=hold_prob)\n",
    "\n",
    "y_pred = normal_full_layer(full_dropout,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Session\n",
    "\n",
    "** Perform the training and test print outs in a Tf session and run your model! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3385777032719622104, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11280806708\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15653021730364466468\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAct = []\n",
    "trainPred = []\n",
    "\n",
    "testAct = []\n",
    "testPred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[954,128,102,102] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_27 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu_28, Variable_60/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_70/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_Mean_70\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_27', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-b9950553f725>\", line 2, in <module>\n    convo_2 = convolutional_layer(convo_1,shape=[2,2,128,128])\n  File \"<ipython-input-10-41c92a076598>\", line 19, in convolutional_layer\n    return tf.nn.relu(conv2d(input_x, W) + b)\n  File \"<ipython-input-10-41c92a076598>\", line 10, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 956, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[954,128,102,102] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_27 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu_28, Variable_60/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_70/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_Mean_70\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[954,128,102,102] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_27 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu_28, Variable_60/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_70/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_Mean_70\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1580532c513b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                  \u001b[0;31m# printing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[954,128,102,102] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_27 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu_28, Variable_60/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_70/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_Mean_70\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_27', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-b9950553f725>\", line 2, in <module>\n    convo_2 = convolutional_layer(convo_1,shape=[2,2,128,128])\n  File \"<ipython-input-10-41c92a076598>\", line 19, in convolutional_layer\n    return tf.nn.relu(conv2d(input_x, W) + b)\n  File \"<ipython-input-10-41c92a076598>\", line 10, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 956, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/cldelahan/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[954,128,102,102] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_27 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu_28, Variable_60/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_70/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_Mean_70\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# config = tf.ConfigProto(gpu_options = gpu_options)\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(10000):\n",
    "        ph = PictureHelper()\n",
    "        batch = ph.next_batch(16)\n",
    "        sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.9})\n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%10 == 0:\n",
    "            #print('Currently on step {}'.format(i))\n",
    "            if (i%50 == 0):\n",
    "                print('Currently on step {}'.format(i))\n",
    "                \n",
    "                x_test2, y_test2 = ph.getTesting(1000) # for testing data\n",
    "                x_train2, y_train2 = ph.next_batch(1000) # for training data\n",
    "\n",
    "                matches = tf.equal(tf.argmax(y_pred, axis = 1), tf.argmax(y_true, axis = 1))\n",
    "                acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "                 # printing accuracy\n",
    "                \n",
    "                test_acc = sess.run(acc,feed_dict={x:x_test2, y_true:y_test2, hold_prob:1.0})\n",
    "                train_acc = sess.run(acc, feed_dict = {x:x_train2, y_true:y_train2, hold_prob:1.0})\n",
    "                print(\"Testing Accuracy: \")\n",
    "                print(test_acc)\n",
    "                \n",
    "                print(\"Training Accuracy: \")\n",
    "                print(train_acc)\n",
    "                \n",
    "                \n",
    "                testPred.append(sess.run(y_pred, feed_dict = {x:x_test2, y_true:y_test2, hold_prob:1.0}))\n",
    "                testAct.append(y_test2)\n",
    "                \n",
    "                trainPred.append(sess.run(y_pred, feed_dict = {x:x_train2, y_true:y_train2, hold_prob:1.0}))\n",
    "                trainAct.append(y_train2)\n",
    "                \n",
    "                data = [testAct, testPred, trainAct, trainPred]\n",
    "                pickle.dump(data, open('results.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Shape\n",
      "(23, 1000, 2)\n",
      "Actual Shape\n",
      "(23, 1000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open('results.p', 'rb'))\n",
    "actual = np.array(data[2])\n",
    "predicted = np.array(data[3])\n",
    "print(\"Predicted Shape\")\n",
    "print(predicted.shape)\n",
    "print(\"Actual Shape\")\n",
    "print(actual.shape)\n",
    "predicted = np.argmax(predicted, axis = 2)\n",
    "actual = np.argmax(actual, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 1 0 1 0 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 1 0 1 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted[-1][:15])\n",
    "print(actual[-1][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches = []\n",
    "for i in range(predicted.shape[0]):\n",
    "    num_matches.append(predicted[i][predicted[i] == actual[i]].size)\n",
    "num_matches = np.array(num_matches)\n",
    "accuracy = num_matches / predicted.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy)\n",
    "plt.title(\"Accuracy vs Batch\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
